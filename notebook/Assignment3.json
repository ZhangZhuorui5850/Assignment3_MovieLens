{"paragraphs":[{"text":"%md\r\n# Assignment 3: User Data Processing with Spark, HDFS, and Cassandra\r\n\r\n**Student Name**: Zhang Zhuorui\r\n**Student ID**: p147459\r\n**Tech Stack**: Apache Spark | Cassandra | HDFS | Zeppelin Notebook\r\n\r\nThe goal of this project is to load user information (`u.user`) from the MovieLens dataset from HDFS, clean it using PySpark, and then store it into Apache Cassandra. User data analysis and visualizations will then be displayed using Zeppelin.\r\n\r\nThis Notebook is organized into the following sections:\r\n\r\n1.  Environment Initialization\r\n2.  Data Reading and Writing to Cassandra\r\n3.  User Data Analysis and Visualization\r\n4.  System Design Analysis (Courseware Extension)\r\n5.  Conclusion and Future Work\r\n6.  Areas for Improvement","user":"anonymous","dateUpdated":"2025-06-19T13:43:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Assignment 3: User Data Processing with Spark, HDFS, and Cassandra</h1>\n<p><strong>Student Name</strong>: Zhang Zhuorui\n<br  /><strong>Student ID</strong>: p147459\n<br  /><strong>Tech Stack</strong>: Apache Spark | Cassandra | HDFS | Zeppelin Notebook</p>\n<p>The goal of this project is to load user information (<code>u.user</code>) from the MovieLens dataset from HDFS, clean it using PySpark, and then store it into Apache Cassandra. User data analysis and visualizations will then be displayed using Zeppelin.</p>\n<p>This Notebook is organized into the following sections:</p>\n<ol>\n<li>Environment Initialization</li>\n<li>Data Reading and Writing to Cassandra</li>\n<li>User Data Analysis and Visualization</li>\n<li>System Design Analysis (Courseware Extension)</li>\n<li>Conclusion and Future Work</li>\n<li>Areas for Improvement</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1750082572939_-1487724027","id":"20250616-140252_2036567657","dateCreated":"2025-06-16T14:02:52+0000","dateStarted":"2025-06-19T13:43:29+0000","dateFinished":"2025-06-19T13:43:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:158"},{"text":"%pyspark\r\nfrom pyspark.sql import SparkSession\r\n\r\nspark = SparkSession.builder \\\r\n    .appName(\"Assignment3_UUser\") \\\r\n    .master(\"local[*]\") \\\r\n    .config(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\r\n    .getOrCreate()\r\n\r\nprint(\"Spark Session 已启动\")\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Spark Session 已启动\n"}]},"apps":[],"jobName":"paragraph_1750082593928_-941518507","id":"20250616-140313_1442481584","dateCreated":"2025-06-16T14:03:13+0000","dateStarted":"2025-06-19T13:33:30+0000","dateFinished":"2025-06-19T13:33:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:159"},{"text":"%md\r\n## Section 1 | Load User Data and Write to Cassandra Table `users`\r\n\r\nWe begin by reading the `u.user` file from HDFS and defining the Spark schema based on the field order and data types.  \r\nNext, the data is converted into a DataFrame and written into the `users` table in Cassandra using the Spark-Cassandra Connector.\r\n\r\nField definitions are as follows:\r\n\r\n**Field Definitions:**\r\n\r\n* **user_id**: Type: `int`, Description: Primary key, unique user identifier\r\n* **age**: Type: `int`, Description: Age\r\n* **gender**: Type: `string`, Description: Gender\r\n* **occupation**: Type: `string`, Description: Occupation\r\n* **zip**: Type: `string`, Description: Zip code","user":"anonymous","dateUpdated":"2025-06-19T13:33:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Section 1 | Load User Data and Write to Cassandra Table <code>users</code></h2>\n<p>We begin by reading the <code>u.user</code> file from HDFS and defining the Spark schema based on the field order and data types.\n<br  />Next, the data is converted into a DataFrame and written into the <code>users</code> table in Cassandra using the Spark-Cassandra Connector.</p>\n<p>Field definitions are as follows:</p>\n<p><strong>Field Definitions:</strong></p>\n<ul>\n<li><strong>user_id</strong>: Type: <code>int</code>, Description: Primary key, unique user identifier</li>\n<li><strong>age</strong>: Type: <code>int</code>, Description: Age</li>\n<li><strong>gender</strong>: Type: <code>string</code>, Description: Gender</li>\n<li><strong>occupation</strong>: Type: <code>string</code>, Description: Occupation</li>\n<li><strong>zip</strong>: Type: <code>string</code>, Description: Zip code</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750082605644_1899097947","id":"20250616-140325_2058799443","dateCreated":"2025-06-16T14:03:25+0000","dateStarted":"2025-06-19T13:33:31+0000","dateFinished":"2025-06-19T13:33:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:160"},{"text":"%pyspark\r\n#1.1 读取 u.user 文件并显示前几行\r\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType\r\n\r\n# 定义 schema\r\nuser_schema = StructType([\r\n    StructField(\"user_id\", IntegerType(), True),\r\n    StructField(\"age\", IntegerType(), True),\r\n    StructField(\"gender\", StringType(), True),\r\n    StructField(\"occupation\", StringType(), True),\r\n    StructField(\"zip\", StringType(), True)\r\n])\r\n\r\n# 从 HDFS 加载数据（字段分隔符是 |\r\nuser_df = spark.read.csv(\r\n    \"hdfs:///user/maria_dev/ml-100k/u.user\",\r\n    sep=\"|\",\r\n    schema=user_schema\r\n)\r\n\r\nuser_df.show(5, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:31+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+---+------+----------+-----+\n|user_id|age|gender|occupation|zip  |\n+-------+---+------+----------+-----+\n|1      |24 |M     |technician|85711|\n|2      |53 |F     |other     |94043|\n|3      |23 |M     |writer    |32067|\n|4      |24 |M     |technician|43537|\n|5      |33 |F     |other     |15213|\n+-------+---+------+----------+-----+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750082615228_-1480536392","id":"20250616-140335_2132032222","dateCreated":"2025-06-16T14:03:35+0000","dateStarted":"2025-06-19T13:33:40+0000","dateFinished":"2025-06-19T13:33:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:161"},{"text":"%pyspark\r\n# 1.2 写入 Cassandra 表 users\r\nuser_df.repartition(1).write \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .option(\"table\", \"users\") \\\r\n    .option(\"keyspace\", \"movielens\") \\\r\n    .mode(\"append\") \\\r\n    .save()\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1750082622791_-204693715","id":"20250616-140342_1037136017","dateCreated":"2025-06-16T14:03:42+0000","dateStarted":"2025-06-19T13:33:40+0000","dateFinished":"2025-06-19T13:33:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:162"},{"text":"%pyspark\r\n# 1.3 回读验证写入是否成功\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"users\", keyspace=\"movielens\") \\\r\n    .load().show(10, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+---+------+-------------+-----+\n|user_id|age|gender|occupation   |zip  |\n+-------+---+------+-------------+-----+\n|79     |39 |F     |administrator|03755|\n|210    |39 |M     |engineer     |03060|\n|505    |27 |F     |other        |20657|\n|16     |21 |M     |entertainment|10309|\n|942    |48 |F     |librarian    |78209|\n|402    |30 |M     |engineer     |95129|\n|63     |31 |M     |marketing    |75240|\n|768    |29 |M     |administrator|12866|\n|725    |21 |M     |student      |91711|\n|642    |18 |F     |student      |95521|\n+-------+---+------+-------------+-----+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750082628652_60798351","id":"20250616-140348_1520659225","dateCreated":"2025-06-16T14:03:48+0000","dateStarted":"2025-06-19T13:33:41+0000","dateFinished":"2025-06-19T13:33:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:163"},{"text":"%md\r\n- Table Name: `users`\r\n- Primary Key Selection: `user_id` (single-field primary key)\r\n- Read Scenarios: Query user details by `user_id`, or for JOIN operations in user profiling analysis\r\n- Write Mode: Append, to prevent overwriting old records\r\n- Corresponding to Week 9 Content: Schema-on-write principle in NoSQL, primary key must be defined","user":"anonymous","dateUpdated":"2025-06-19T13:33:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<ul>\n<li>Table Name: <code>users</code></li>\n<li>Primary Key Selection: <code>user_id</code> (single-field primary key)</li>\n<li>Read Scenarios: Query user details by <code>user_id</code>, or for JOIN operations in user profiling analysis</li>\n<li>Write Mode: Append, to prevent overwriting old records</li>\n<li>Corresponding to Week 9 Content: Schema-on-write principle in NoSQL, primary key must be defined</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750082635266_236643922","id":"20250616-140355_153304882","dateCreated":"2025-06-16T14:03:55+0000","dateStarted":"2025-06-19T13:33:34+0000","dateFinished":"2025-06-19T13:33:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:164"},{"text":"%md\r\n## Section 2 | Load Rating Data and Write to Cassandra Table `ratings`\r\n\r\nThe file `u.data` contains 4 columns: User ID, Movie ID, Rating Value, and Timestamp (UNIX seconds).\r\nTo ensure the data can be used for time-based queries and sorting, we will convert the timestamp field to `timestamp` type before writing to Cassandra.\r\n\r\nTable Schema Design:\r\n\r\n* **movie_id**: Type: `int`, Description: Partition key\r\n* **user_id**: Type: `int`, Description: Clustering key, for compound primary key\r\n* **rating**: Type: `int`, Description: Rating value\r\n* **ts**: Type: `timestamp`, Description: Rating timestamp (converted from UNIX timestamp)\r\n\r\nThe primary key is defined as `(movie_id, user_id)`, indicating that each user can have only one rating record per movie.","user":"anonymous","dateUpdated":"2025-06-19T13:33:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Section 2 | Load Rating Data and Write to Cassandra Table <code>ratings</code></h2>\n<p>The file <code>u.data</code> contains 4 columns: User ID, Movie ID, Rating Value, and Timestamp (UNIX seconds).\n<br  />To ensure the data can be used for time-based queries and sorting, we will convert the timestamp field to <code>timestamp</code> type before writing to Cassandra.</p>\n<p>Table Schema Design:</p>\n<ul>\n<li><strong>movie_id</strong>: Type: <code>int</code>, Description: Partition key</li>\n<li><strong>user_id</strong>: Type: <code>int</code>, Description: Clustering key, for compound primary key</li>\n<li><strong>rating</strong>: Type: <code>int</code>, Description: Rating value</li>\n<li><strong>ts</strong>: Type: <code>timestamp</code>, Description: Rating timestamp (converted from UNIX timestamp)</li>\n</ul>\n<p>The primary key is defined as <code>(movie_id, user_id)</code>, indicating that each user can have only one rating record per movie.</p>\n"}]},"apps":[],"jobName":"paragraph_1750083684807_1448316732","id":"20250616-142124_1360104819","dateCreated":"2025-06-16T14:21:24+0000","dateStarted":"2025-06-19T13:33:36+0000","dateFinished":"2025-06-19T13:33:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:165"},{"text":"%pyspark\n# 2.2 PySpark 读取 + 类型转换代码\nfrom pyspark.sql.types import StructType, StructField, IntegerType, LongType\nfrom pyspark.sql.functions import col, from_unixtime\n\n# 定义 schema\nschema_rating = StructType([\n    StructField(\"user_id\", IntegerType(), True),\n    StructField(\"movie_id\", IntegerType(), True),\n    StructField(\"rating\", IntegerType(), True),\n    StructField(\"unix_ts\", LongType(), True)\n])\n\n# 加载数据\nrating_raw_df = spark.read.csv(\n    \"hdfs:///user/maria_dev/ml-100k/u.data\",\n    sep=\"\\t\",\n    schema=schema_rating\n)\n\n# 转换 UNIX 时间戳为 timestamp\nrating_df = rating_raw_df.withColumn(\n    \"ts\", from_unixtime(col(\"unix_ts\")).cast(\"timestamp\")\n).select(\"movie_id\", \"user_id\", \"rating\", \"ts\")\n\nrating_df.show(5, truncate=False)\n\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------+------+-------------------+\n|movie_id|user_id|rating|ts                 |\n+--------+-------+------+-------------------+\n|242     |196    |3     |1997-12-04 15:55:49|\n|302     |186    |3     |1998-04-04 19:22:22|\n|377     |22     |1     |1997-11-07 07:18:36|\n|51      |244    |2     |1997-11-27 05:02:03|\n|346     |166    |1     |1998-02-02 05:33:16|\n+--------+-------+------+-------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750083840376_-973106787","id":"20250616-142400_711110270","dateCreated":"2025-06-16T14:24:00+0000","dateStarted":"2025-06-19T13:33:41+0000","dateFinished":"2025-06-19T13:33:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:166"},{"text":"%pyspark\r\n# 2.3 写入 Cassandra 表 ratings\r\nrating_df.repartition(1).write \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .option(\"table\", \"ratings\") \\\r\n    .option(\"keyspace\", \"movielens\") \\\r\n    .mode(\"append\") \\\r\n    .save()\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1750083893374_-1227749263","id":"20250616-142453_321287398","dateCreated":"2025-06-16T14:24:53+0000","dateStarted":"2025-06-19T13:33:42+0000","dateFinished":"2025-06-19T13:34:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:167"},{"text":"%pyspark\r\n# 2.4 验证写入成功\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"ratings\", keyspace=\"movielens\") \\\r\n    .load().show(10, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------+------+-------------------+\n|movie_id|user_id|rating|ts                 |\n+--------+-------+------+-------------------+\n|1201    |90     |5     |1998-03-31 22:34:47|\n|79      |1      |4     |1997-09-24 03:47:45|\n|79      |5      |3     |1997-09-30 16:11:35|\n|79      |6      |3     |1997-12-31 20:39:07|\n|79      |7      |4     |1998-03-31 13:51:01|\n|79      |8      |4     |1997-11-12 19:18:06|\n|79      |11     |4     |1998-04-06 23:36:23|\n|79      |13     |3     |1997-12-14 22:49:06|\n|79      |16     |5     |1997-10-24 21:05:22|\n|79      |18     |4     |1997-11-21 16:57:30|\n+--------+-------+------+-------------------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750083922550_465023304","id":"20250616-142522_1058322042","dateCreated":"2025-06-16T14:25:22+0000","dateStarted":"2025-06-19T13:33:43+0000","dateFinished":"2025-06-19T13:34:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:168"},{"text":"%md\n**Primary Key Design Explanation**:\n- Partition Key: `movie_id`, to facilitate aggregating ratings for each movie\n- Clustering Key: `user_id`, to enable quick lookup of whether a user has rated a specific movie\n- Using a compound primary key `(movie_id, user_id)` prevents users from rating the same movie multiple times\n\n**Timestamp Field Conversion**:\n- Use `from_unixtime()` to convert `int` to Spark-supported `timestamp`\n- Automatically maps to `timestamp` type when writing to Cassandra, facilitating subsequent time analysis\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p><strong>Primary Key Design Explanation</strong>:</p>\n<ul>\n<li>Partition Key: <code>movie_id</code>, to facilitate aggregating ratings for each movie</li>\n<li>Clustering Key: <code>user_id</code>, to enable quick lookup of whether a user has rated a specific movie</li>\n<li>Using a compound primary key <code>(movie_id, user_id)</code> prevents users from rating the same movie multiple times</li>\n</ul>\n<p><strong>Timestamp Field Conversion</strong>:</p>\n<ul>\n<li>Use <code>from_unixtime()</code> to convert <code>int</code> to Spark-supported <code>timestamp</code></li>\n<li>Automatically maps to <code>timestamp</code> type when writing to Cassandra, facilitating subsequent time analysis</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750083933511_-1991598423","id":"20250616-142533_378127165","dateCreated":"2025-06-16T14:25:33+0000","dateStarted":"2025-06-19T13:33:38+0000","dateFinished":"2025-06-19T13:33:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:169"},{"text":"%md\r\n## Section 3 | Load Movie Information and Write to Cassandra Table `movies`\r\n\r\nThe file `u.item` contains detailed movie information, including:\r\n\r\n- `movie_id` (Primary Key)\r\n- `title` (Movie Title)\r\n- 19 boolean flags indicating whether the movie belongs to corresponding genres (e.g., Action, Comedy)\r\n\r\nTo improve readability and facilitate subsequent analysis, we will convert the genres into a **set<text> type**, storing multiple genres for each movie.\r\n\r\n\r\n**Field Definitions:**\r\n\r\n* **movie_id**: Type: `int`, Description: Primary key\r\n* **title**: Type: `text`, Description: Movie title\r\n* **genres**: Type: `set<text>`, Description: Set of genres (e.g., `{'Action', 'Drama'}`)","user":"anonymous","dateUpdated":"2025-06-19T13:33:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Section 3 | Load Movie Information and Write to Cassandra Table <code>movies</code></h2>\n<p>The file <code>u.item</code> contains detailed movie information, including:</p>\n<ul>\n<li><code>movie_id</code> (Primary Key)</li>\n<li><code>title</code> (Movie Title)</li>\n<li>19 boolean flags indicating whether the movie belongs to corresponding genres (e.g., Action, Comedy)</li>\n</ul>\n<p>To improve readability and facilitate subsequent analysis, we will convert the genres into a <strong>set<text> type</strong>, storing multiple genres for each movie.</p>\n<p><strong>Field Definitions:</strong></p>\n<ul>\n<li><strong>movie_id</strong>: Type: <code>int</code>, Description: Primary key</li>\n<li><strong>title</strong>: Type: <code>text</code>, Description: Movie title</li>\n<li><strong>genres</strong>: Type: <code>set&lt;text&gt;</code>, Description: Set of genres (e.g., <code>{'Action', 'Drama'}</code>)</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750083955021_1039884134","id":"20250616-142555_833973014","dateCreated":"2025-06-16T14:25:55+0000","dateStarted":"2025-06-19T13:33:38+0000","dateFinished":"2025-06-19T13:33:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:170"},{"text":"%pyspark\r\n# 3.2 加载 u.genre 映射表\r\n# 加载 genre 映射编号 → 类型名（例如 0 → Action）\r\ngenre_map = (\r\n    spark.read.text(\"hdfs:///user/maria_dev/ml-100k/u.genre\")\r\n    .filter(\"value != ''\")\r\n    .rdd.map(lambda r: r[0].split(\"|\"))\r\n    .map(lambda kv: (int(kv[1]), kv[0]))\r\n    .collectAsMap()\r\n)\r\n\r\nprint(genre_map)  # 可查看 genre 索引和名称映射关系\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{0: u'unknown', 1: u'Action', 2: u'Adventure', 3: u'Animation', 4: u\"Children's\", 5: u'Comedy', 6: u'Crime', 7: u'Documentary', 8: u'Drama', 9: u'Fantasy', 10: u'Film-Noir', 11: u'Horror', 12: u'Musical', 13: u'Mystery', 14: u'Romance', 15: u'Sci-Fi', 16: u'Thriller', 17: u'War', 18: u'Western'}\n"}]},"apps":[],"jobName":"paragraph_1750084106601_-1479083884","id":"20250616-142826_157587633","dateCreated":"2025-06-16T14:28:26+0000","dateStarted":"2025-06-19T13:34:45+0000","dateFinished":"2025-06-19T13:34:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:171"},{"text":"%pyspark\r\n# 3.3 加载 u.item 文件并解析 genre 位\r\nfrom pyspark.sql.types import *\r\n\r\n# genre 列（注意此处不使用 f-string，改为 format 兼容 Zeppelin）\r\ngenre_fields = [StructField(\"g{}\".format(i), IntegerType(), True) for i in range(19)]\r\n\r\n# 构造 schema（前 5 列 + 19 个 genre 布尔列）\r\nprefix_fields = [\r\n    StructField(\"movie_id\", IntegerType(), True),\r\n    StructField(\"title\", StringType(), True),\r\n    StructField(\"release_date\", StringType(), True),\r\n    StructField(\"video_release_date\", StringType(), True),\r\n    StructField(\"imdb_url\", StringType(), True)\r\n]\r\n\r\nschema_item = StructType(prefix_fields + genre_fields)\r\n\r\nitem_raw = spark.read.csv(\r\n    \"hdfs:///user/maria_dev/ml-100k/u.item\",\r\n    sep=\"|\",\r\n    schema=schema_item\r\n)\r\n\r\nitem_raw.show(5, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:39+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-----------------+------------+------------------+------------------------------------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n|movie_id|title            |release_date|video_release_date|imdb_url                                              |g0 |g1 |g2 |g3 |g4 |g5 |g6 |g7 |g8 |g9 |g10|g11|g12|g13|g14|g15|g16|g17|g18|\n+--------+-----------------+------------+------------------+------------------------------------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n|1       |Toy Story (1995) |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Toy%20Story%20(1995) |0  |0  |0  |1  |1  |1  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |\n|2       |GoldenEye (1995) |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?GoldenEye%20(1995)   |0  |1  |1  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |1  |0  |0  |\n|3       |Four Rooms (1995)|01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |1  |0  |0  |\n|4       |Get Shorty (1995)|01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0  |1  |0  |0  |0  |1  |0  |0  |1  |0  |0  |0  |0  |0  |0  |0  |0  |0  |0  |\n|5       |Copycat (1995)   |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Copycat%20(1995)     |0  |0  |0  |0  |0  |0  |1  |0  |1  |0  |0  |0  |0  |0  |0  |0  |1  |0  |0  |\n+--------+-----------------+------------+------------------+------------------------------------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750084127016_399306219","id":"20250616-142847_15307079","dateCreated":"2025-06-16T14:28:47+0000","dateStarted":"2025-06-19T13:34:47+0000","dateFinished":"2025-06-19T13:34:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:172"},{"text":"%pyspark\r\n# 3.4 转换 genre 位 → set<text>\r\n# 定义转换函数\r\ndef extract_genres(row):\r\n    genres = [genre_map[i] for i in range(19) if row[\"g{}\".format(i)] == 1]\r\n    return (row[\"movie_id\"], row[\"title\"], genres)  # 不建议用 set，DataFrame不支持\r\n\r\n# RDD 转换为 (movie_id, title, [genre1, genre2, ...])\r\nmovie_rdd = item_raw.rdd.map(extract_genres)\r\n\r\n# 转换为 DataFrame\r\nmovie_df = spark.createDataFrame(movie_rdd, [\"movie_id\", \"title\", \"genres\"])\r\n\r\n# 展示前5行\r\nmovie_df.show(5, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:39+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-----------------+-------------------------------+\n|movie_id|title            |genres                         |\n+--------+-----------------+-------------------------------+\n|1       |Toy Story (1995) |[Animation, Children's, Comedy]|\n|2       |GoldenEye (1995) |[Action, Adventure, Thriller]  |\n|3       |Four Rooms (1995)|[Thriller]                     |\n|4       |Get Shorty (1995)|[Action, Comedy, Drama]        |\n|5       |Copycat (1995)   |[Crime, Drama, Thriller]       |\n+--------+-----------------+-------------------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750084416933_-2097331038","id":"20250616-143336_1892117224","dateCreated":"2025-06-16T14:33:36+0000","dateStarted":"2025-06-19T13:34:47+0000","dateFinished":"2025-06-19T13:34:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"text":"%pyspark\n# 3.5 写入 Cassandra 表 movies\nmovie_df.repartition(1).write \\\n    .format(\"org.apache.spark.sql.cassandra\") \\\n    .option(\"table\", \"movies\") \\\n    .option(\"keyspace\", \"movielens\") \\\n    .mode(\"append\") \\\n    .save()\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:40+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1750085028446_-1512210039","id":"20250616-144348_454034492","dateCreated":"2025-06-16T14:43:48+0000","dateStarted":"2025-06-19T13:34:48+0000","dateFinished":"2025-06-19T13:34:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:174"},{"text":"%pyspark\r\n# 3.6 验证写入是否成功\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"movies\", keyspace=\"movielens\") \\\r\n    .load().show(10, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------------------+------------------------------------------+\n|movie_id|genres             |title                                     |\n+--------+-------------------+------------------------------------------+\n|1201    |[Documentary]      |Marlene Dietrich: Shadow and Light (1996) |\n|79      |[Action, Thriller] |Fugitive, The (1993)                      |\n|210     |[Action, Adventure]|Indiana Jones and the Last Crusade (1989) |\n|1289    |[Romance]          |Jack and Sarah (1995)                     |\n|505     |[Mystery, Thriller]|Dial M for Murder (1954)                  |\n|1611    |[Comedy]           |Intimate Relations (1996)                 |\n|16      |[Comedy, Romance]  |French Twist (Gazon maudit) (1995)        |\n|1061    |[Comedy, Drama]    |Evening Star, The (1996)                  |\n|1211    |[Drama, Romance]   |Blue Sky (1994)                           |\n|1468    |[Drama]            |Cure, The (1995)                          |\n+--------+-------------------+------------------------------------------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750085295782_1947819851","id":"20250616-144815_1119537824","dateCreated":"2025-06-16T14:48:15+0000","dateStarted":"2025-06-19T13:34:48+0000","dateFinished":"2025-06-19T13:34:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:175"},{"text":"%md\n- Each movie can correspond to multiple genres, thus a `set<text>` type is used for storage.\n- The `genres` field parsing is based on the `u.genre` mapping, avoiding direct use of boolean bit numbering.\n- Can be JOINed with the `ratings` table via `movie_id` for convenient analysis of rating performance across different genres.\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<ul>\n<li>Each movie can correspond to multiple genres, thus a <code>set&lt;text&gt;</code> type is used for storage.</li>\n<li>The <code>genres</code> field parsing is based on the <code>u.genre</code> mapping, avoiding direct use of boolean bit numbering.</li>\n<li>Can be JOINed with the <code>ratings</code> table via <code>movie_id</code> for convenient analysis of rating performance across different genres.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750085312011_-99798472","id":"20250616-144832_1323968151","dateCreated":"2025-06-16T14:48:32+0000","dateStarted":"2025-06-19T13:33:41+0000","dateFinished":"2025-06-19T13:33:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176"},{"text":"%md\r\n## Section 4 | Answering Five Specific Query Questions (Assignment i–v)\r\n\r\nIn this section, we will use Spark SQL to answer the following five questions by querying the three previously written tables:\r\n\r\n1. The average rating for each movie  \r\n2. The top 10 movies by average rating (including titles)  \r\n3. The favorite movie genre of each active user  \r\n4. All users under the age of 20  \r\n5. Users aged between 30 and 40 whose occupation is \"scientist\"  \r\n\r\nTo simplify the analysis, we first register the three tables as temporary views (TempView).\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Section 4 | Answering Five Specific Query Questions (Assignment i–v)</h2>\n<p>In this section, we will use Spark SQL to answer the following five questions by querying the three previously written tables:</p>\n<ol>\n<li>The average rating for each movie</li>\n<li>The top 10 movies by average rating (including titles)</li>\n<li>The favorite movie genre of each active user</li>\n<li>All users under the age of 20</li>\n<li>Users aged between 30 and 40 whose occupation is &ldquo;scientist&rdquo;</li>\n</ol>\n<p>To simplify the analysis, we first register the three tables as temporary views (TempView).</p>\n"}]},"apps":[],"jobName":"paragraph_1750085327443_-1729964237","id":"20250616-144847_780704081","dateCreated":"2025-06-16T14:48:47+0000","dateStarted":"2025-06-19T13:33:42+0000","dateFinished":"2025-06-19T13:33:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:177"},{"text":"%pyspark\r\n# 4.2 注册三张 Cassandra 表为视图\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"users\", keyspace=\"movielens\") \\\r\n    .load().createOrReplaceTempView(\"users\")\r\n\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"ratings\", keyspace=\"movielens\") \\\r\n    .load().createOrReplaceTempView(\"ratings\")\r\n\r\nspark.read \\\r\n    .format(\"org.apache.spark.sql.cassandra\") \\\r\n    .options(table=\"movies\", keyspace=\"movielens\") \\\r\n    .load().createOrReplaceTempView(\"movies\")\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:42+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1750085471690_1141815233","id":"20250616-145111_2092472687","dateCreated":"2025-06-16T14:51:11+0000","dateStarted":"2025-06-19T13:34:51+0000","dateFinished":"2025-06-19T13:34:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:178"},{"text":"%md\n### (i) Average Rating for Each Movie\n\n- This query uses the `ratings` table, grouping by `movie_id` and calculating `AVG(rating)`.\n- The results can be used for subsequent filtering of highly-rated movies.\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>(i) Average Rating for Each Movie</h3>\n<ul>\n<li>This query uses the <code>ratings</code> table, grouping by <code>movie_id</code> and calculating <code>AVG(rating)</code>.</li>\n<li>The results can be used for subsequent filtering of highly-rated movies.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750301384824_1947563343","id":"20250619-024944_39986249","dateCreated":"2025-06-19T02:49:44+0000","dateStarted":"2025-06-19T13:33:43+0000","dateFinished":"2025-06-19T13:33:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:179"},{"text":"%pyspark\r\n# (i) 每部电影的平均评分\r\nspark.sql(\"\"\"\r\nSELECT r.movie_id, m.title, ROUND(AVG(r.rating), 2) AS avg_rating\r\nFROM ratings r\r\nJOIN movies m ON r.movie_id = m.movie_id\r\nGROUP BY r.movie_id, m.title\r\nORDER BY r.movie_id\r\n\"\"\").show(10)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+--------------------+----------+\n|movie_id|               title|avg_rating|\n+--------+--------------------+----------+\n|       1|    Toy Story (1995)|      3.88|\n|       2|    GoldenEye (1995)|      3.21|\n|       3|   Four Rooms (1995)|      3.03|\n|       4|   Get Shorty (1995)|      3.55|\n|       5|      Copycat (1995)|       3.3|\n|       6|Shanghai Triad (Y...|      3.58|\n|       7|Twelve Monkeys (1...|       3.8|\n|       8|         Babe (1995)|       4.0|\n|       9|Dead Man Walking ...|       3.9|\n|      10|  Richard III (1995)|      3.83|\n+--------+--------------------+----------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750085572194_1298362063","id":"20250616-145252_918646647","dateCreated":"2025-06-16T14:52:52+0000","dateStarted":"2025-06-19T13:34:51+0000","dateFinished":"2025-06-19T13:35:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:180"},{"text":"%md\r\n### (ii) Top Ten Movies with Highest Average Rating\r\n\r\n- Join `ratings` and `movies` tables to get movie titles by movie ID.\r\n- Sort by `avg_rating DESC` to select the top 10 movies with the highest ratings.","user":"anonymous","dateUpdated":"2025-06-19T13:41:18+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":115.391,"optionOpen":false}}},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>(ii) Top Ten Movies with Highest Average Rating</h3>\n<ul>\n<li>Join <code>ratings</code> and <code>movies</code> tables to get movie titles by movie ID.</li>\n<li>Sort by <code>avg_rating DESC</code> to select the top 10 movies with the highest ratings.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750085615643_1806892839","id":"20250616-145335_1552830834","dateCreated":"2025-06-16T14:53:35+0000","dateStarted":"2025-06-19T13:41:07+0000","dateFinished":"2025-06-19T13:41:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:181"},{"text":"%pyspark\r\n# (ii) 平均评分最高的前十部影片（含标题）\r\nspark.sql(\"\"\"\r\nSELECT r.movie_id, m.title, ROUND(AVG(r.rating), 2) AS avg_rating\r\nFROM ratings r\r\nJOIN movies m ON r.movie_id = m.movie_id\r\nGROUP BY r.movie_id, m.title\r\nORDER BY avg_rating DESC\r\n\"\"\").show(n = 10, truncate = False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------------------------------------------------+----------+\n|movie_id|title                                            |avg_rating|\n+--------+-------------------------------------------------+----------+\n|1201    |Marlene Dietrich: Shadow and Light (1996)        |5.0       |\n|1122    |They Made Me a Criminal (1939)                   |5.0       |\n|1189    |Prefontaine (1997)                               |5.0       |\n|814     |Great Day in Harlem, A (1994)                    |5.0       |\n|1293    |Star Kid (1997)                                  |5.0       |\n|1599    |Someone Else's America (1995)                    |5.0       |\n|1467    |Saint of Fort Washington, The (1993)             |5.0       |\n|1536    |Aiqing wansui (1994)                             |5.0       |\n|1653    |Entertaining Angels: The Dorothy Day Story (1996)|5.0       |\n|1500    |Santa with Muscles (1996)                        |5.0       |\n+--------+-------------------------------------------------+----------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750085645696_-2027499375","id":"20250616-145405_1721253315","dateCreated":"2025-06-16T14:54:05+0000","dateStarted":"2025-06-19T13:34:54+0000","dateFinished":"2025-06-19T13:35:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:182"},{"text":"%md\r\n### (iii) For each user with at least 50 ratings, identify their favorite movie genre\r\n- First, filter the \"active users\" group (those with ≥ 50 ratings).\r\n- Then, extract the movie genres rated by these users through a JOIN operation.\r\n- Use `explode()` to flatten the collection and count the most frequently occurring genres.","user":"anonymous","dateUpdated":"2025-06-19T13:33:46+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>(iii) For each user with at least 50 ratings, identify their favorite movie genre</h3>\n<ul>\n<li>First, filter the &ldquo;active users&rdquo; group (those with ≥ 50 ratings).</li>\n<li>Then, extract the movie genres rated by these users through a JOIN operation.</li>\n<li>Use <code>explode()</code> to flatten the collection and count the most frequently occurring genres.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750085682664_1106508635","id":"20250616-145442_1882564010","dateCreated":"2025-06-16T14:54:42+0000","dateStarted":"2025-06-19T13:33:48+0000","dateFinished":"2025-06-19T13:33:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:183"},{"text":"%pyspark\r\n#  (iii) 每个评分≥50次的用户最喜欢的电影类型\r\nspark.sql(\"\"\"\r\nWITH active_users AS (\r\n    SELECT user_id\r\n    FROM ratings\r\n    GROUP BY user_id\r\n    HAVING COUNT(*) >= 50\r\n),\r\nexploded_genres AS (\r\n    SELECT r.user_id, genre\r\n    FROM ratings r\r\n    JOIN active_users a ON r.user_id = a.user_id\r\n    JOIN movies m ON m.movie_id = r.movie_id\r\n    LATERAL VIEW explode(m.genres) AS genre\r\n),\r\ngenre_counts AS (\r\n    SELECT user_id, genre, COUNT(*) AS count\r\n    FROM exploded_genres\r\n    GROUP BY user_id, genre\r\n),\r\nranked_genres AS (\r\n    SELECT *,\r\n           ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY count DESC) AS rank\r\n    FROM genre_counts\r\n)\r\nSELECT g.user_id, u.gender, u.occupation, g.genre, g.count\r\nFROM ranked_genres g\r\nJOIN users u ON g.user_id = u.user_id\r\nWHERE rank = 1\r\nORDER BY g.count DESC\r\n\r\n\"\"\").show(10, truncate=False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:33:48+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":344,"optionOpen":false}}},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------+----------+------+-----+\n|user_id|gender|occupation|genre |count|\n+-------+------+----------+------+-----+\n|655    |F     |healthcare|Drama |410  |\n|405    |F     |healthcare|Drama |309  |\n|537    |M     |engineer  |Drama |251  |\n|450    |F     |educator  |Drama |237  |\n|13     |M     |educator  |Drama |218  |\n|234    |M     |retired   |Drama |213  |\n|416    |F     |student   |Drama |212  |\n|279    |M     |programmer|Comedy|211  |\n|201    |M     |writer    |Drama |196  |\n|393    |M     |student   |Comedy|191  |\n+-------+------+----------+------+-----+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750085734932_-64789611","id":"20250616-145534_698566433","dateCreated":"2025-06-16T14:55:34+0000","dateStarted":"2025-06-19T13:35:14+0000","dateFinished":"2025-06-19T13:35:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:184"},{"text":"%md\r\n### (iv) All users under the age of 20 \r\n- Simply filter the `users` table, selecting records where the age field is less than 20.","user":"anonymous","dateUpdated":"2025-06-19T13:39:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>(iv) All users under the age of 20</h3>\n<ul>\n<li>Simply filter the <code>users</code> table, selecting records where the age field is less than 20.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750085800959_-511575029","id":"20250616-145640_437058619","dateCreated":"2025-06-16T14:56:40+0000","dateStarted":"2025-06-19T13:39:32+0000","dateFinished":"2025-06-19T13:39:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:185"},{"text":"%pyspark\r\n\r\nspark.sql(\"\"\"\r\nSELECT * FROM users\r\nWHERE age < 20\r\n\"\"\").show(n = 10, truncate = False)\r\n","user":"anonymous","dateUpdated":"2025-06-19T13:34:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+---+------+-------------+-----+\n|user_id|age|gender|occupation   |zip  |\n+-------+---+------+-------------+-----+\n|642    |18 |F     |student      |95521|\n|588    |18 |F     |student      |93063|\n|30     |7  |M     |student      |55436|\n|528    |18 |M     |student      |55104|\n|674    |13 |F     |student      |55337|\n|375    |17 |M     |entertainment|37777|\n|851    |18 |M     |other        |29646|\n|859    |18 |F     |other        |06492|\n|813    |14 |F     |student      |02136|\n|52     |18 |F     |student      |55105|\n+-------+---+------+-------------+-----+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750300881433_1786990591","id":"20250619-024121_2051669195","dateCreated":"2025-06-19T02:41:21+0000","dateStarted":"2025-06-19T13:35:19+0000","dateFinished":"2025-06-19T13:35:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:186"},{"text":"%md\r\n### (v) Users aged between 30 and 40 whose occupation is \"scientist\"\r\n- Use `BETWEEN` and `=` to combine filtering conditions.","user":"anonymous","dateUpdated":"2025-06-19T13:34:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>(v) Users aged between 30 and 40 whose occupation is &ldquo;scientist&rdquo;</h3>\n<ul>\n<li>Use <code>BETWEEN</code> and <code>=</code> to combine filtering conditions.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1750300902557_1948594997","id":"20250619-024142_1034760362","dateCreated":"2025-06-19T02:41:42+0000","dateStarted":"2025-06-19T13:34:50+0000","dateFinished":"2025-06-19T13:34:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:187"},{"text":"%pyspark\n# (v) 年龄在 30–40 岁之间且职业为 scientist 的用户\nspark.sql(\"\"\"\nSELECT * FROM users\nWHERE age BETWEEN 30 AND 40 AND occupation = 'scientist'\n\"\"\").show(n = 10, truncate=False)\n","user":"anonymous","dateUpdated":"2025-06-19T13:34:50+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+---+------+----------+-----+\n|user_id|age|gender|occupation|zip  |\n+-------+---+------+----------+-----+\n|730    |31 |F     |scientist |32114|\n|74     |39 |M     |scientist |T8H1N|\n|183    |33 |M     |scientist |27708|\n|107    |39 |M     |scientist |60466|\n|918    |40 |M     |scientist |70116|\n|337    |37 |M     |scientist |10522|\n|272    |33 |M     |scientist |53706|\n|430    |38 |M     |scientist |98199|\n|643    |39 |M     |scientist |55122|\n|543    |33 |M     |scientist |95123|\n+-------+---+------+----------+-----+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1750086075716_-1537129538","id":"20250616-150115_779190606","dateCreated":"2025-06-16T15:01:15+0000","dateStarted":"2025-06-19T13:35:34+0000","dateFinished":"2025-06-19T13:35:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:188"},{"text":"%md\r\n## Section 5 | Summary and Future Work\r\n\r\n### roject Summary\r\n\r\nIn this Assignment 3, I have completed the following key tasks:\r\n\r\n1.  Used Apache Zeppelin to build an interactive Notebook, achieving an interpretable and reproducible data processing workflow.\r\n2.  Used PySpark to load three sub-files of the MovieLens dataset (u.user, u.data, u.item) from HDFS.\r\n3.  Combined Schema definition and cleaning logic to structure the data into DataFrames.\r\n4.  Utilized the Spark-Cassandra Connector to write three types of data (users, ratings, movies) into Cassandra tables (users, ratings, movies).\r\n5.  Designed reasonable primary keys and data types, particularly employing a composite primary key `(movie_id, user_id)` in `ratings`.\r\n6.  Implemented five core query tasks, covering single-table aggregation, JOINs, multi-level filtering, set unnesting, and other complex analytical operations.\r\n7.  Supplemented each analysis step with chart displays and Markdown documentation to ensure a clear and logically complete Notebook structure.\r\n\r\n---\r\n\r\n### Course Knowledge Application Points\r\n\r\n| Concept | Application Location |\r\n|---|---|\r\n| CAP Theory | Selected Cassandra (AP model) for high-availability distributed writes  |\r\n| Hadoop HDFS | Raw data loading paths based on HDFS storage structure  |\r\n| ETL Process | Extract (HDFS) → Transform (Spark cleansing) → Load (Cassandra)  |\r\n| Distributed System Challenges | Used `repartition(1)` to control concurrent writes, solving the risk of Zeppelin write failures  |\r\n| NoSQL Data Modeling | Used `set<text>` collection type to store movie genres, reasonably designed primary keys for optimized query performance  |\r\n\r\n---","user":"anonymous","dateUpdated":"2025-06-19T13:40:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Section 5 | Summary and Future Work</h2>\n<h3>roject Summary</h3>\n<p>In this Assignment 3, I have completed the following key tasks:</p>\n<ol>\n<li>Used Apache Zeppelin to build an interactive Notebook, achieving an interpretable and reproducible data processing workflow.</li>\n<li>Used PySpark to load three sub-files of the MovieLens dataset (u.user, u.data, u.item) from HDFS.</li>\n<li>Combined Schema definition and cleaning logic to structure the data into DataFrames.</li>\n<li>Utilized the Spark-Cassandra Connector to write three types of data (users, ratings, movies) into Cassandra tables (users, ratings, movies).</li>\n<li>Designed reasonable primary keys and data types, particularly employing a composite primary key <code>(movie_id, user_id)</code> in <code>ratings</code>.</li>\n<li>Implemented five core query tasks, covering single-table aggregation, JOINs, multi-level filtering, set unnesting, and other complex analytical operations.</li>\n<li>Supplemented each analysis step with chart displays and Markdown documentation to ensure a clear and logically complete Notebook structure.</li>\n</ol>\n<hr />\n<h3>Course Knowledge Application Points</h3>\n<p>| Concept | Application Location |\n<br  />|&mdash;|&mdash;|\n<br  />| CAP Theory | Selected Cassandra (AP model) for high-availability distributed writes  |\n<br  />| Hadoop HDFS | Raw data loading paths based on HDFS storage structure  |\n<br  />| ETL Process | Extract (HDFS) → Transform (Spark cleansing) → Load (Cassandra)  |\n<br  />| Distributed System Challenges | Used <code>repartition(1)</code> to control concurrent writes, solving the risk of Zeppelin write failures  |\n<br  />| NoSQL Data Modeling | Used <code>set&lt;text&gt;</code> collection type to store movie genres, reasonably designed primary keys for optimized query performance  |</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1750086098910_-1325887068","id":"20250616-150138_1471696882","dateCreated":"2025-06-16T15:01:38+0000","dateStarted":"2025-06-19T13:40:51+0000","dateFinished":"2025-06-19T13:40:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:189"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2025-06-19T13:34:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1750088194721_-443854886","id":"20250616-153634_1929521914","dateCreated":"2025-06-16T15:36:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:190"}],"name":"Ass3","id":"2KZ7QD2T4","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}